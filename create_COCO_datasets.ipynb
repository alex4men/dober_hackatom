{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_yolo_data(\n",
    "    samples,\n",
    "    export_dir,\n",
    "    classes,\n",
    "    label_field = \"ground_truth\",\n",
    "    split = None\n",
    "    ):\n",
    "\n",
    "    if type(split) == list:\n",
    "        splits = split\n",
    "        for split in splits:\n",
    "            export_yolo_data(\n",
    "                samples,\n",
    "                export_dir,\n",
    "                classes,\n",
    "                label_field,\n",
    "                split\n",
    "            )\n",
    "    else:\n",
    "        if split is None:\n",
    "            split_view = samples\n",
    "            split = \"val\"\n",
    "        else:\n",
    "            split_view = samples.match_tags(split)\n",
    "\n",
    "        split_view.export(\n",
    "            export_dir=export_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            label_field=label_field,\n",
    "            classes=classes,\n",
    "            split=split\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yolo_detections(\n",
    "    samples,\n",
    "    prediction_field,\n",
    "    prediction_filepath,\n",
    "    class_list\n",
    "    ):\n",
    "\n",
    "    prediction_filepaths = samples.values(prediction_filepath)\n",
    "    yolo_detections = [read_yolo_detections_file(pf) for pf in prediction_filepaths]\n",
    "    detections =  [convert_yolo_detections_to_fiftyone(yd, class_list) for yd in yolo_detections]\n",
    "    samples.set_values(prediction_field, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '/media/datasets/DATASET'\n",
    "FRAMES_ROOT = os.path.join(DATASET_ROOT, 'FRAMES')\n",
    "DATASET_CFG_PATH = 'metadata/set_utf.cfg'\n",
    "IMG_WIDTH = 960\n",
    "IMG_HEIGHT = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [str(x) for x in range(14)]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = defaultdict(list)\n",
    "\n",
    "with open(os.path.join(DATASET_ROOT, DATASET_CFG_PATH), 'r') as fd:\n",
    "    fname = ''\n",
    "    for line in fd:\n",
    "        # print(line)\n",
    "        line = line.strip()\n",
    "        if line.split('.')[-1] == 'frame':\n",
    "            fname = os.path.join(FRAMES_ROOT, *line.split('\\\\'))\n",
    "            fname = fname.replace('.frame', '.bmp')\n",
    "            # print(fname)\n",
    "            # print(os.path.isfile(os.path.join(FRAMES_ROOT, fname)))\n",
    "        else:\n",
    "            # fill objects info\n",
    "            x_px, y_px, cls = list(map(int, line.replace(' ', '').split(',')))\n",
    "            x = x_px / IMG_WIDTH\n",
    "            y = y_px / IMG_HEIGHT\n",
    "            dataset_dict[fname].append({'x': x, 'y': y, 'x_px': x_px, 'y_px': y_px, 'cls': cls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 0.8427083333333333, 'y': 0.56, 'x_px': 809, 'y_px': 336, 'cls': 3},\n",
       " {'x': 0.6260416666666667,\n",
       "  'y': 0.49833333333333335,\n",
       "  'x_px': 601,\n",
       "  'y_px': 299,\n",
       "  'cls': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['/media/datasets/DATASET/FRAMES/0/1538/frame0006.bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 7808/7808 [1.2s elapsed, 0s remaining, 6.7K samples/s]         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://0.0.0.0:5151/?notebook=True&subscription=56ffd488-8ff9-4909-98a9-0cd8f104c749\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f52d6a97af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = fo.Dataset.from_images_dir(\n",
    "    images_dir=FRAMES_ROOT,\n",
    "    name='hackatom',\n",
    "    overwrite=True\n",
    "    )\n",
    "dataset.persistent = True\n",
    "session = fo.launch_app(dataset, address=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_view = dataset.take(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0% ||--------------|    0/7808 [35.7ms elapsed, ? remaining, ? samples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 7808/7808 [18.7s elapsed, 0s remaining, 431.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(preds_view):\n",
    "        if sample.filepath in dataset_dict.keys():\n",
    "            keypoints = []\n",
    "            detections = []\n",
    "            for kp in dataset_dict[sample.filepath]:\n",
    "                keypoints.append(\n",
    "                    fo.Keypoint(\n",
    "                        label=str(kp['cls']),\n",
    "                        points=[(kp['x'], kp['y'])],\n",
    "                    )\n",
    "                )\n",
    "                x_tl_px = (kp['x_px'] - 80) / IMG_WIDTH\n",
    "                y_tl_px = (kp['y_px'] - 80) / IMG_HEIGHT\n",
    "                width = 160 / IMG_WIDTH\n",
    "                height = 160 / IMG_HEIGHT\n",
    "                detections.append(\n",
    "                    fo.Detection(\n",
    "                        label=str(kp['cls']),\n",
    "                        bounding_box=[x_tl_px, y_tl_px, width, height]\n",
    "                    )\n",
    "                )\n",
    "            # sample['keypoints'] = fo.Keypoints(keypoints=keypoints)\n",
    "            sample['ground_truth'] = fo.Detections(detections=detections)\n",
    "            sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty = preds_view.match(\n",
    "{\n",
    "  \"$and\": [\n",
    "    {\n",
    "      \"ground_truth.detections.label\": {\n",
    "        \"$in\": [\n",
    "          \"1\",\n",
    "          \"10\",\n",
    "          \"11\",\n",
    "          \"12\",\n",
    "          \"13\",\n",
    "          \"2\",\n",
    "          \"3\",\n",
    "          \"4\",\n",
    "          \"5\",\n",
    "          \"6\",\n",
    "          \"7\",\n",
    "          \"8\",\n",
    "          \"9\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = non_empty[:1200]\n",
    "train_dataset = non_empty[1200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 2752/2752 [15.2s elapsed, 0s remaining, 180.3 samples/s]      \n",
      "Directory '../data_train_balanced' already exists; export will be merged with existing files\n",
      " 100% |█████████████████| 688/688 [4.0s elapsed, 0s remaining, 181.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# ## split into train and val\n",
    "# four.random_split(\n",
    "#     train_dataset,\n",
    "#     {\"train\": 0.8, \"val\": 0.2}\n",
    "# )\n",
    "\n",
    "# ## export in YOLO format\n",
    "# export_yolo_data(\n",
    "#     train_dataset,\n",
    "#     \"../data_train_balanced\",\n",
    "#     classes,\n",
    "#     split = [\"train\", \"val\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1200/1200 [6.4s elapsed, 0s remaining, 192.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# ## export in YOLO format\n",
    "# export_yolo_data(\n",
    "#     test_dataset,\n",
    "#     \"../data_test_balanced\",\n",
    "#     classes\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!yolo task=detect mode=train model=yolov8l.pt data=../data_train/dataset.yaml epochs=300 patience=30 imgsz=640 batch=192 device=0,1,2,3,4,5 workers=44 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!yolo task=detect mode=predict model=runs/detect/train14/weights/best.pt source=../data_test_balanced/images/val device=0,1,2,3,4,5 save_txt=True save_conf=True imgsz=608,960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = test_dataset.values(\"runs/detect/predict3/labels\")\n",
    "prediction_filepaths = [get_prediction_filepath(fp, run_number=2) for fp in filepaths]\n",
    "\n",
    "test_dataset.set_values(\n",
    "    \"yolov8m_640\",\n",
    "    prediction_filepaths\n",
    ")\n",
    "\n",
    "add_yolo_detections(\n",
    "    test_dataset,\n",
    "    \"yolov8m_640\",\n",
    "    \"yolov8n_bird_det_filepath\",\n",
    "    classes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
